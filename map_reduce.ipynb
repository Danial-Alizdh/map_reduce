{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='installing-spark'></a>\n",
    "### Installing Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Dependencies:\n",
    "\n",
    "\n",
    "1.   Java 8\n",
    "2.   Apache Spark with hadoop and\n",
    "3.   Findspark (used to locate the spark in the system)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
    "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Environment Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drive  sample_data  spark-3.1.1-bin-hadoop3.2  spark-3.1.1-bin-hadoop3.2.tgz\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://42cf642a33a8:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>wordcount</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f2af011f2e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_address = '/content/drive/MyDrive/Tehran Polytechnic/BigData/HW01/P1/data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(p1_address, 'r')\n",
    "data = []\n",
    "while True:\n",
    "    line = file1.readline()\n",
    "    if not line:\n",
    "        break\n",
    "    line_values = line.split(' ')\n",
    "    data.append([line_values[0], line_values[1:-2]])\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-4e909653-37c8-4715-b66f-c4ea570acffa\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5988</td>\n",
       "      <td>[748, 1722, 3752, 4655, 5743, 1872, 3413, 5527...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5989</td>\n",
       "      <td>[4080, 4264, 4446, 3779, 2430, 2297, 6169, 353...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5982</td>\n",
       "      <td>[217, 595, 1194, 3308, 2940, 1815, 794, 1503, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5983</td>\n",
       "      <td>[1165, 3836, 4361, 1282, 716, 4289, 4646, 6300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5980</td>\n",
       "      <td>[2731, 3712, 1587, 6084, 2472, 2546, 6313, 875...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6584</th>\n",
       "      <td>5637</td>\n",
       "      <td>[2557, 3805, 4131, 2650, 4016, 5716]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6585</th>\n",
       "      <td>5630</td>\n",
       "      <td>[1165, 3868, 3614, 3615, 5421, 661, 133, 4452,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6586</th>\n",
       "      <td>5631</td>\n",
       "      <td>[3949, 3934, 5294, 3889, 5333, 3352]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6587</th>\n",
       "      <td>5632</td>\n",
       "      <td>[2912, 4366, 2040, 1602, 4395, 133, 403, 2178]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6588</th>\n",
       "      <td>5633</td>\n",
       "      <td>[1121, 3059, 2948, 6084, 3424, 1891, 958, 3365...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6589 rows Ã— 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e909653-37c8-4715-b66f-c4ea570acffa')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-4e909653-37c8-4715-b66f-c4ea570acffa button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-4e909653-37c8-4715-b66f-c4ea570acffa');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       key                                              value\n",
       "0     5988  [748, 1722, 3752, 4655, 5743, 1872, 3413, 5527...\n",
       "1     5989  [4080, 4264, 4446, 3779, 2430, 2297, 6169, 353...\n",
       "2     5982  [217, 595, 1194, 3308, 2940, 1815, 794, 1503, ...\n",
       "3     5983  [1165, 3836, 4361, 1282, 716, 4289, 4646, 6300...\n",
       "4     5980  [2731, 3712, 1587, 6084, 2472, 2546, 6313, 875...\n",
       "...    ...                                                ...\n",
       "6584  5637               [2557, 3805, 4131, 2650, 4016, 5716]\n",
       "6585  5630  [1165, 3868, 3614, 3615, 5421, 661, 133, 4452,...\n",
       "6586  5631               [3949, 3934, 5294, 3889, 5333, 3352]\n",
       "6587  5632     [2912, 4366, 2040, 1602, 4395, 133, 403, 2178]\n",
       "6588  5633  [1121, 3059, 2948, 6084, 3424, 1891, 958, 3365...\n",
       "\n",
       "[6589 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data, columns=['key', 'value'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('p1.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+\n",
      "| key|               value|\n",
      "+----+--------------------+\n",
      "|5988|[748, 1722, 3752,...|\n",
      "|5989|[4080, 4264, 4446...|\n",
      "|5982|[217, 595, 1194, ...|\n",
      "|5983|[1165, 3836, 4361...|\n",
      "|5980|[2731, 3712, 1587...|\n",
      "|5981|[3569, 5353, 4087...|\n",
      "|5986|[2658, 3712, 2650...|\n",
      "|5987|[2614, 5716, 1765...|\n",
      "|5984|[590, 4898, 745, ...|\n",
      "|5985|[3233, 2254, 212,...|\n",
      "|6294|[4898, 1127, 3220...|\n",
      "| 270|[2658, 3003, 3805...|\n",
      "| 271|[4935, 5716, 4309...|\n",
      "| 272|[2717, 4363, 4088...|\n",
      "| 273|[1165, 5013, 5110...|\n",
      "| 274|[3920, 5310, 4024...|\n",
      "| 275|[4366, 3373, 1587...|\n",
      "| 276|[2277, 5251, 4806...|\n",
      "| 277|[1068, 3495, 6194...|\n",
      "| 278|[1145, 667, 2650,...|\n",
      "+----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['key', 'value']\n",
    "df_spark = spark.createDataFrame(data=data, schema=columns)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "| key|len|\n",
      "+----+---+\n",
      "|5988| 47|\n",
      "|5989| 39|\n",
      "|5982| 41|\n",
      "|5983| 13|\n",
      "|5980| 23|\n",
      "|5981| 16|\n",
      "|5986|141|\n",
      "|5987| 80|\n",
      "|5984| 40|\n",
      "|5985| 18|\n",
      "|6294| 12|\n",
      "| 270| 41|\n",
      "| 271|  8|\n",
      "| 272| 44|\n",
      "| 273| 57|\n",
      "| 274|409|\n",
      "| 275| 46|\n",
      "| 276| 14|\n",
      "| 277| 15|\n",
      "| 278|122|\n",
      "+----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd2 = df_spark.rdd.map(lambda x: (x[0], len(x[1])))\n",
    "df2 = rdd2.toDF([\"key\",\"len\"])\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "| key|sum(len)|\n",
      "+----+--------+\n",
      "| 691|       5|\n",
      "|1159|      10|\n",
      "|3959|     141|\n",
      "|1572|      34|\n",
      "|2294|      13|\n",
      "|1090|       3|\n",
      "|3606|     170|\n",
      "|3414|       6|\n",
      "| 296|      16|\n",
      "|4821|      15|\n",
      "|2162|      40|\n",
      "|1436|       8|\n",
      "|1512|      10|\n",
      "|6194|      13|\n",
      "|6240|      10|\n",
      "| 829|      36|\n",
      "|2136|       5|\n",
      "|5645|      19|\n",
      "|2069|     262|\n",
      "| 467|       0|\n",
      "+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = df2.groupBy('key').sum('len')\n",
    "x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(key='859', sum(len)=1929),\n",
       " Row(key='5306', sum(len)=1737),\n",
       " Row(key='2664', sum(len)=1524),\n",
       " Row(key='5716', sum(len)=1423),\n",
       " Row(key='6306', sum(len)=1391)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x.rdd.sortBy(lambda x: x[1]).collect()[::-1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[129]\n",
      "[29]\n",
      "[118]\n"
     ]
    }
   ],
   "source": [
    "print(x.rdd.lookup('1748'))\n",
    "print(x.rdd.lookup('5633'))\n",
    "print(x.rdd.lookup('3469'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
